#!/usr/bin/env python

from dynamic_reconfigure.parameter_generator_catkin import *
import json

PACKAGE="next_best_view"

gen = ParameterGenerator()
sphereSampling = gen.add_group("Sphere Sampling")
spaceSampling = gen.add_group("Space Sampling")
camera = gen.add_group("Camera")
robotModel = gen.add_group("Robot Model")
rating = gen.add_group("Rating")
hypothesisUpdater = gen.add_group("hypothesis Updater")
vis = gen.add_group("Visualization")
moduleChooser = gen.add_group("Module Chooser")
worldHelper = gen.add_group("World Helper")
other = gen.add_group("Other")

# Name, Type, Reconfiguration level, 
# Description, 
# Default, Min, Max

# sphere sampling
sphereSampling.add("sampleSizeUnitSphereSampler", int_t, 0b1 << 1, 
  "number of samples created by SpiralApproxUnitSphereSampler", 
  128, 1, 1000000000)

# space sampling
spaceSampling.add("radius", double_t, 0b1 << 3, 
  "radius of hexagons, used by MapBasedHexagonSpaceSampler", 
  0.75, 0.001, 10.0)
spaceSampling.add("sampleSizeMapBasedRandomSpaceSampler", int_t, 0b1 << 3, 
  "number of samples created by MapBasedRandomSpaceSampler", 
  100, 1, 1000000000)
  
# mapHelper
robotModel.add("colThresh", double_t, (0b1 << 2), 
  "", 
  45.0, 0.1, 100.0)

# camera
# ncp and fcp are also used by robot model
camera.add("ncp", double_t, (0b1 << 4) | (0b1 << 5), 
  "Distance to NearClippingPlane in meter", 
  .5, 0.0, 2.0)
camera.add("fcp", double_t, (0b1 << 4) | (0b1 << 5), 
  "Distance to FarClippingPlane in meter", 
  5.0, 1.0, 10.0)
camera.add("fovx", double_t, 0b1 << 4, 
  "angle of horizontal field of view in degree", 
  62.5, 10, 180)
camera.add("fovy", double_t, 0b1 << 4, 
  "angle of vertical field of view in degree", 
  48.9, 10, 180)
camera.add("speedFactorRecognizer", double_t, 0b1 << 4, 
  "time usage for object detection in seconds per object", 
  5.0, 0.1, 1000.0)

# robotmodel
# some of these might be not be applied immediately, because they are read from rosparam instead of config struct.
robotModel.add("useGlobalPlanner", bool_t, 0b1 << 5, 
  "", 
  True)
robotModel.add("tolerance", double_t, 0b1 << 5, 
  "", 
  0.00003, 0.0, 10.0)
robotModel.add("panMin", double_t, 0b1 << 5, 
  "", 
  -60, -360, 0)
robotModel.add("panMax", double_t, 0b1 << 5, 
  "", 
  60, 0, 360)
robotModel.add("tiltMin", double_t, 0b1 << 5, 
  "", 
  -45, -360, 0)
robotModel.add("tiltMax", double_t, 0b1 << 5, 
  "", 
  45, 0, 360)
robotModel.add("mSigma", double_t, 0b1 << 5, 
  "", 
  1.0)
robotModel.add("panAngleSamplingStepsPerIteration", int_t, 0b1 << 5, 
  "", 
  20, 1, 1000000000)
robotModel.add("inverseKinematicIterationAccuracy", double_t, 0b1 << 5, 
  "", 
  0.005, 0.0, 10.0)

# rating
rating.add("mOmegaUtility", double_t, 0b1 << 6, 
  "coefficient for the usage", 
  1, 0.0, 1000.0)
# rot/tilt/pan are used by MILDRobotModel
rating.add("mOmegaPan", double_t, (0b1 << 6) | (0b1 << 5), 
  "coefficient for the rotation of the pan axis of the PTU", 
  1, 0.0, 1000.0)
rating.add("mOmegaTilt", double_t, (0b1 << 6) | (0b1 << 5), 
  "coefficient for the rotation of the tilt axis of the PTU", 
  1, 0.0, 1000.0)
rating.add("mOmegaRot", double_t, (0b1 << 6) | (0b1 << 5), 
  "coefficient for the rotation of the base", 
  1, 0.0, 1000.0)
rating.add("mOmegaBase", double_t, 0b1 << 6, 
  "coefficient for the movement of the base", 
  1, 0.0, 1000.0)
rating.add("mOmegaRecognizer", double_t, 0b1 << 6, 
  "", 
  1, 0.0, 1000.0)
rating.add("useOrientationUtility", bool_t, 0b1 << 6,
  "",
  True)
rating.add("useProximityUtility", bool_t, 0b1 << 6,
  "",
  True)
rating.add("useSideUtility", bool_t, 0b1 << 6,
  "",
  True)

rating.add("mRatingNormalAngleThreshold", double_t, 0b1 << 6,
  "angle threshold, used to rate angles which have a rating greater than 0",
  45.0, 0.0, 180.0)

# hypothesis updater
hypothesisUpdater.add("mHypothesisUpdaterAngleThreshold", double_t, 0b1 << 6,
  "angle threshold, used to rate angles between hypothesis nad the camera viewport to determine if hypothesis should be removed",
  60.0, 0.0, 180.0)

# vis
vis.add("show_space_sampling", bool_t, 0b1 << 0, 
  "", 
  False)
vis.add("show_point_cloud", bool_t, 0b1 << 0, 
  "", 
  False)
vis.add("show_frustum_point_cloud", bool_t, 0b1 << 0, 
  "", 
  False)
vis.add("show_frustum_marker_array", bool_t, 0b1 << 0, 
  "", 
  False)
vis.add("show_normals", bool_t, 0b1 << 0, 
  "", 
  False)
vis.add("visualizeIK", bool_t, 0b1 << 0, 
  "", 
  False)

# module chooser
sphereSamplingConsts = [ 
  gen.const("SpiralApproxUnitSphereSampler",        int_t, 1, "")
]
sphereSamplingEnum = gen.enum(sphereSamplingConsts, "An enum to set the sphere sampling module")
moduleChooser.add("sphereSamplerId", int_t, 0b1 << 1, "sphere sampling module", 1, 1, len(sphereSamplingConsts), edit_method=sphereSamplingEnum)


spaceSamplingConsts = [
  gen.const("MapBasedHexagonSpaceSampler",        int_t, 1, ""),
  gen.const("MapBasedRandomSpaceSampler",         int_t, 2, ""),
  gen.const("PlaneSubSpaceSampler",               int_t, 3, ""),
  gen.const("Raytracing2DBasedSpaceSampler",      int_t, 4, ""),
  gen.const("HypothesisSpaceSampler",             int_t, 5, "")
]
spaceSamplingEnum = gen.enum(spaceSamplingConsts, "An enum to set the space sampling module")
moduleChooser.add("spaceSamplerId", int_t, 0b1 << 3, "space sampling module", 1, 1, len(spaceSamplingConsts), edit_method=spaceSamplingEnum)


spaceSamplingPatternConsts = [
  gen.const("HexagonSpaceSamplePattern",          int_t, 1, "")
]
spaceSamplingPatternEnum = gen.enum(spaceSamplingPatternConsts, "An enum to set the space sampling pattern module")
moduleChooser.add("spaceSamplePatternId", int_t, 0b1 << 3, "space sample pattern module", 1, 1, len(spaceSamplingPatternConsts), edit_method=spaceSamplingPatternEnum)


cameraConsts = [ 
  gen.const("3DRaytracingBasedBasedStereoCameraModelFilter",  int_t, 1, ""),
  gen.const("StereoCameraModelFilter",                        int_t, 2, ""),
  gen.const("3DRaytracingBasedSingleCameraModelFilter",       int_t, 3, ""),
  gen.const("SingleCameraModelFilter",                        int_t, 4, "")
]
cameraEnum = gen.enum(cameraConsts, "An enum to set the camera model")
moduleChooser.add("cameraFilterId", int_t, 0b1 << 4, "camera model", 2, 1, len(cameraConsts), edit_method=cameraEnum)


robotConsts = [ 
  gen.const("MILDRobotModelWithExactIK",          int_t, 1, ""),
  gen.const("MILDRobotModelWithApproximatedIK",   int_t, 2, "")
]
robotModelEnum = gen.enum(robotConsts, "An enum to set the robot model")
moduleChooser.add("robotModelId", int_t, 0b1 << 5, "robot model", 1, 1, len(robotConsts), edit_method=robotModelEnum)


ratingConsts = [ 
  gen.const("DefaultRatingModule",          int_t, 1, "")
]
ratingEnum = gen.enum(ratingConsts, "An enum to set the rating module")
moduleChooser.add("ratingModuleId", int_t, 0b1 << 6, "rating module", 1, 1, len(ratingConsts), edit_method=ratingEnum)


hypothesisUpdaterConsts = [ 
  gen.const("PerspectiveHypothesisUpdater",       int_t, 1, ""),
  gen.const("DefaultHypothesisUpdater",           int_t, 2, "")
]
hypothesisUpdaterEnum = gen.enum(hypothesisUpdaterConsts, "An enum to set the hypothesis updater module")
moduleChooser.add("hypothesisUpdaterId", int_t, 0b1 << 7, "hypothesis updater module", 1, 1, len(hypothesisUpdaterConsts), edit_method=hypothesisUpdaterEnum)


# World Helper
worldHelper.add("worldFilePath", str_t, 0b1 << 2, 
  "",
  "")

worldHelper.add("voxelSize", double_t, 0b1 << 2, 
  "",
  0.01, 0.001, 1.0)

worldHelper.add("worldHeight", double_t, 0b1 << 2, 
  "",
  3.0, 0.0, 10.0)
worldHelper.add("visualizeRaytracing", bool_t, 0b1 << 2,
  "",
  False)

# other
# mCropboxListFilePath is level 8, so cropbox xml is only reloaded if a cropboxsetting is changed
other.add("enableCropBoxFiltering", bool_t, 0b1 << 0, 
  "", 
  False)
other.add("mCropBoxListFilePath", str_t, 0b1 << 8, 
  "", 
  "NONE")
other.add("enableIntermediateObjectWeighting", bool_t, 0b1 << 0, 
  "", 
  False)

# iteration
other.add("maxIterationSteps", int_t, 0b1 << 0, 
  "", 
  20, 1, 100000)
other.add("minIterationSteps", int_t, 0b1 << 0, 
  "", 
  0, 0, 100000)

#filters
other.add("enableClusterFilter", bool_t, 0b1 << 0, 
  "filters space samples, based on cluster information which are extracted from hypothesis", 
  True)
other.add("enableMapFilter", bool_t, 0b1 << 0, 
  "filters space samples based on map information, samples that cannot be reached because the position is occupied", 
  True)
other.add("enableKDTreeFilter", bool_t, 0b1 << 0, 
  "filters space samples, which have no nearby hypothesis", 
  True)

other.add("nRatingThreads", int_t, 0b1 << 0,
  "number of rating threads used to rate samples. negative numbers use a special function to determine a good number of threads",
  -1, 1, 100)

  # other features
other.add("removeInvalidNormals", bool_t, 0b1 << 0,
  "wheter normals that cannot be reached by a viewport should be kept or removed",
  True)
other.add("cacheResults", bool_t, 0b1 << 0,
  "if results should be cached for next nbv calls with the same pointcloud",
  True)
other.add("enableClustering", bool_t, 0b1 << 0,
  "if hypothesis pointcloud should be clustered",
  True)
other.add("useMinUtility", bool_t, 0b1 << 0,
  "wheter next best view should require a minimum utility",
  True)
other.add("epsilon", double_t, 0b1 << 0,
  "",
  0.001, 10e-10, 1)
other.add("debugLevels", str_t, 0b1 << 0, 
  "", 
  "NONE")

exit(gen.generate(PACKAGE, "next_best_view", "DynamicParameters"))